# Load Packages
# For graphs and visualizations
library(ggplot2)
# Split Data into Test and Train Set
library(caTools)
# Recursive Partitioning and Regression Trees (Decision Trees)
library(rpart)
# To visualize decision tree
library(rattle)
library(tinytex)

# Import Data
getwd()
loandata = read.csv("Loan_Delinquent_Dataset.csv")

# Exploratory Data Analysis

# Sanity checks
# Look at the first and last few rows to ensure that the data is read in properly
head(loandata)
tail(loandata)
dim(loandata)
colnames(loandata)

# Descriptive Statistics
# Structure of data
str(loandata)

# Change vaiables with character datatype to factor
loandata$isDelinquent = as.factor(loandata$isDelinquent)
loandata$term = as.factor(loandata$term)
loandata$gender = as.factor(loandata$gender)
loandata$purpose = as.factor(loandata$purpose)
loandata$home_ownership = as.factor(loandata$home_ownership)
loandata$age = as.factor(loandata$age)
loandata$FICO = as.factor(loandata$FICO)

# Remove ID Column
loandata = loandata[, -1] # Dropping ID Column

# Summary of dataset
summary(loandata)

# Data Cleaning
levels(loandata$purpose)
#Merge the purpose levels 'Other' and 'other'
levels(loandata$purpose) = c("Car","House","Medical","Other","Other","Personal","Wedding")
levels(loandata$purpose)
summary(loandata)

# Univariate and Bivariate analysis
#Distribution of the dependent variable
prop.table(table(loandata$isDelinquent))
summary(loandata)

ggplot(loandata, aes(fill = isDelinquent, x = FICO)) +
  geom_bar(position="fill")
ggplot(loandata, aes(fill = isDelinquent, x = term)) +
  geom_bar(position="fill")
ggplot(loandata, aes(fill = isDelinquent, x = purpose)) +
  geom_bar(position="fill")
ggplot(loandata, aes(fill = isDelinquent, x = home_ownership)) +
  geom_bar(position="fill")
ggplot(loandata, aes(fill = isDelinquent, x = gender)) +
  geom_bar(position="fill")
ggplot(loandata, aes(fill = isDelinquent, x = age)) +
  geom_bar(position="fill")

# **** Optional ****
ggplot(loandata, aes(fill = FICO, x = home_ownership)) +
  geom_bar(position="fill") +
  scale_fill_manual(values = c("purple", "pink"))
ggplot(loandata, aes(fill = FICO, x = gender)) +
  geom_bar(position="fill") +
  scale_fill_manual(values = c("purple", "pink"))
ggplot(loandata, aes(fill = FICO, x = age)) +
  geom_bar(position="fill") +
  scale_fill_manual(values = c("purple", "pink"))

chisq.test(loandata$FICO,loandata$home_ownership) #Chi-sq test between FICO and Home Ownership
chisq.test(loandata$FICO,loandata$gender) #Chi-sq test between FICO and Gender
chisq.test(loandata$FICO,loandata$age) #Chi-sq test between FICO and Age

# Split into train and test
set.seed(1000) #To ensure reproducibility

sample <- sample.split(loandata$isDelinquent,SplitRatio = 0.7)
train <- subset(loandata,sample == TRUE)
test <- subset(loandata,sample == FALSE)

nrow(train)
nrow(test)

# Check that the distribution of the dependent variable is similar in train and test sets
prop.table(table(loandata$isDelinquent))
prop.table(table(train$isDelinquent))
prop.table(table(test$isDelinquent))

# Build a CART model on the train dataset
# One of the benefits of decision tree training is that you can stop training
# based on several thresholds.

# Setting the control parameters (to control the growth of the tree)

# minsplit - min # of obs that must exist in a node in order for a split to be attempted
# minbucket - the minimum number of observations in any terminal leaf node
# cp - complexity parameter
# xval - number of cross-validations

# The initial minsplit and minbucket parameters are set using general thumb rules
# minsplit = 2-3% of data
# minbucket = minsplit/3

min_split = 0.2*nrow(train)
min_split
min_bucket = min_split/3
min_bucket

r.ctrl = rpart.control(minsplit = min_split, minbucket = min_bucket, cp = 0, xval = 10)

# Building the CART model

# formula - response variable~predictor variables
# data - dataset
# method - "class" - for classification, "anova" for regression
# control - tree control parameters

model1 <- rpart(formula = isDelinquent~., data = train, method = "class", control = r.ctrl)
model1

# Visualise the decision tree
#Displaying the decision tree
fancyRpartPlot(model1)

model1$variable.importance
# Variable importance is generally computed based on the corresponding reduction of predictive accuracy
# when the predictor of interest is removed.

# Model Validation
# Predicting on the train dataset
train_predict.class1 <- predict(model1, train, type="class") # Predicted Classes
train_predict.score1 <- predict(model1, train) # Predicted Probabilities

# Create confusion matrix for train data predictions
tab.train1 = table(train$isDelinquent, train_predict.class1)
tab.train1

# Accuracy on train data
accuracy.train1 = sum(diag(tab.train1)) / sum(tab.train1)
accuracy.train1

# Model Tuning
# Let us ease the control parameter restrictions to check if we can get a better better fit
r.ctrl2 = rpart.control(minsplit = 500, minbucket = 150, cp = 0, xval = 10)

# Building the CART model
model2 <- rpart(formula = isDelinquent~., data = train, method = "class", control = r.ctrl2)
model2

# Visualise the decision tree
#Displaying the decision tree
fancyRpartPlot(model2)

# Model Validation
# Predicting on the train dataset
train_predict.class2 <- predict(model2, train, type="class") # Predicted Classes
train_predict.score2 <- predict(model2, train) # Predicted Probabilities

# Create confusion matrix for train data predictions
tab.train2 = table(train$isDelinquent, train_predict.class2)
tab.train2

# Accuracy on train data
accuracy.train2 = sum(diag(tab.train2)) / sum(tab.train2)
accuracy.train2

model2$variable.importance

# Model Evaluation

# MODEL 1
# Predicting on the test dataset using MODEL 1
test_predict.class1 <- predict(model1, test, type="class") # Predicted Classes
test_predict.score1 <- predict(model1, test) # Predicted Probabilities

# Create confusion matrix for test data predictions (using MODEL 1)
tab.test1 = table(test$isDelinquent, test_predict.class1)
tab.test1

# Accuracy on train data (MODEL 1 predictions)
accuracy.test1 = sum(diag(tab.test1)) / sum(tab.test1)
accuracy.test1

# MODEL 2
# Predicting on the test dataset using MODEL 2
test_predict.class2 <- predict(model2, test, type="class") # Predicted Classes
test_predict.score2 <- predict(model2, test) # Predicted Probabilities

# Create confusion matrix for test data predictions (using MODEL 2)
tab.test2 = table(test$isDelinquent, test_predict.class2)
tab.test2

# Accuracy on train data (MODEL 2 predictions)
accuracy.test2 = sum(diag(tab.test2)) / sum(tab.test2)
accuracy.test2

# Comparing Models
Model_Name = c("Baseline", "Model1", "Model2")
Train_Accuracy_perc = c(66, accuracy.train1*100, accuracy.train2*100)
Test_Accuracy_perc = c(66, accuracy.test1*100, accuracy.test2*100)
output = data.frame(Model_Name,Train_Accuracy_perc,Test_Accuracy_perc)
output
